{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageColor, ImageFont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 52453\n",
      "{'train': 36589, 'val': 5320, 'test': 10544}\n"
     ]
    }
   ],
   "source": [
    "dataset_keys = ('train', 'val', 'test')\n",
    "dataset_sizes = dict()\n",
    "for dataset in dataset_keys:\n",
    "    with open(f'splits/{dataset}.txt') as f:\n",
    "        size = len(f.readlines())\n",
    "        dataset_sizes[dataset] = size\n",
    "\n",
    "print(f'total size: {sum(dataset_sizes.values())}')\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapillaryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms, dataset_key, num_images):\n",
    "        \"\"\" \n",
    "        dataset_key (string): \"train\", \"test\" or \"val\" \n",
    "        num_images (int): in range 1 to len(dataset)\n",
    "        \"\"\"\n",
    "        assert dataset_key in dataset_keys\n",
    "        assert num_images > 0 and num_images <= dataset_sizes[dataset_key]\n",
    "\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.dataset_key = dataset_key\n",
    "        self.dataset = list(sorted(os.listdir(os.path.join(root, dataset_key, \"images\"))))[:num_images]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images\n",
    "        image_key = self.dataset[idx]\n",
    "        img_path = os.path.join(self.root, self.dataset_key, \"images\", image_key)\n",
    "        \n",
    "        # find annotations\n",
    "        with open(os.path.join('annotations', f'{image_key[:-4]}.json'), 'r') as fid:\n",
    "            anno = json.load(fid)\n",
    "\n",
    "        with Image.open(img_path) as img:\n",
    "            img = img.convert(\"RGB\")\n",
    "\n",
    "            # get bounding box coordinates\n",
    "            rects = Image.new('RGBA', img.size)\n",
    "            #rects_draw = ImageDraw.Draw(rects)\n",
    "\n",
    "            boxes = []\n",
    "            labels = []\n",
    "            for obj in anno['objects']:\n",
    "                xmin = obj['bbox']['xmin']\n",
    "                ymin = obj['bbox']['ymin']\n",
    "                xmax = obj['bbox']['xmax']\n",
    "                ymax = obj['bbox']['ymax']\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "                labels.append(obj['label'])\n",
    "\n",
    "            # convert everything into a torch.Tensor\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "\n",
    "            # there is only one class\n",
    "            labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "            masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "            image_id = torch.tensor([idx])\n",
    "            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "            # suppose all instances are not crowd\n",
    "            iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "            target = {}\n",
    "            target[\"boxes\"] = boxes\n",
    "            target[\"labels\"] = labels\n",
    "            target[\"masks\"] = masks\n",
    "            target[\"image_id\"] = image_id\n",
    "            target[\"area\"] = area\n",
    "            target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return image_key, img_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataset = MapillaryDataset(root=\"\", transforms=None, dataset_key=\"train\", num_images=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'width': 4160,\n",
       " 'height': 3120,\n",
       " 'ispano': False,\n",
       " 'objects': [{'key': '489lm30wc63tjtupe1e2q1',\n",
       "   'label': 'other-sign',\n",
       "   'bbox': {'xmin': 2657.890625,\n",
       "    'ymin': 1013.0859375,\n",
       "    'xmax': 2695.46875,\n",
       "    'ymax': 1051.171875},\n",
       "   'properties': {'barrier': False,\n",
       "    'occluded': True,\n",
       "    'out-of-frame': False,\n",
       "    'exterior': False,\n",
       "    'ambiguous': True,\n",
       "    'included': False,\n",
       "    'direction-or-information': False,\n",
       "    'highway': False,\n",
       "    'dummy': False}},\n",
       "  {'key': 'jwoggy96u43g4ad6o09ee2',\n",
       "   'label': 'other-sign',\n",
       "   'bbox': {'xmin': 2641.640625,\n",
       "    'ymin': 1028.3203125,\n",
       "    'xmax': 2683.28125,\n",
       "    'ymax': 1064.12109375},\n",
       "   'properties': {'barrier': False,\n",
       "    'occluded': False,\n",
       "    'out-of-frame': False,\n",
       "    'exterior': False,\n",
       "    'ambiguous': True,\n",
       "    'included': False,\n",
       "    'direction-or-information': False,\n",
       "    'highway': False,\n",
       "    'dummy': False}}]}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f6e09e3246ecccd0d3f58158facd97045b8a1da7daad17c641ae091f3fb288a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
